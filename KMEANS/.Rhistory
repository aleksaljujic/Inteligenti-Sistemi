# Parametar stringsAsFactors = F sprečava R da automatski konvertuje string promenljive u faktore.
# To je važno jer želimo sami da kontrolišemo kada i kako se kategorijske promenljive
# pretvaraju u faktore (što je kritično za algoritme klasifikacije).
data <- read.csv("travel-times.csv", stringsAsFactors = F)
# Funkcija str() daje strukturu dataseta:
# prikazuje broj redova i kolona, tip svake kolone (integer, numeric, character, factor),
# kao i prvih nekoliko vrednosti. Ovo je osnovni korak u razumevanju podataka.
str(data)
# Funkcija summary() daje osnovne deskriptivne statistike za svaku kolonu:
# za numeričke kolone to su min, 1. kvartil, medijana, mean, 3. kvartil, max,
# dok za kategorijske prikazuje učestalosti.
# Ove informacije pomažu da se stekne uvid u distribuciju podataka i eventualne anomalije.
summary(data)
# ------------------------------------------------------------
# 2. PROVERA I OBRADA NEDOSTAJUCIH VREDNOSTI
# ------------------------------------------------------------
# Nedostajuće vrednosti mogu biti kodirane na različite načine: kao "", "-", " ", ili formalni NA.
# Ako ih ne obradimo, algoritmi mašinskog učenja će prijaviti grešku jer očekuju kompletne podatke.
# colSums() sabira koliko se puta pojavljuje svaki od ovih obrazaca po kolonama.
colSums(data == "" | data == "-" | data == " " | is.na(data))
# Uklanjamo kolone koje nisu relevantne za modeliranje (Date, StartTime, DayOfWeek).
# Ove promenljive ne nose prediktivnu vrednost, a zadržavanjem bismo mogli da unesemo šum
# ili da komplikujemo model bez realne koristi.
data$Date <- NULL
data$StartTime <- NULL
#data$DayOfWeek <- NULL
# ------------------------------------------------------------
# 3. RAD SA KATEGORIJSKOM PROMENLJIVOM GoingTo
# ------------------------------------------------------------
# Provera tipa podataka u koloni (da bismo znali da li je string ili faktor).
class(data$GoingTo)
# Pregled učestalosti vrednosti u koloni GoingTo.
# Ako ima praznih vrednosti, ovde ih lako primetimo.
table(data$GoingTo)
# Pretvaramo kolonu u character radi fleksibilnije manipulacije.
data$GoingTo <- as.character(data$GoingTo)
# Imputacija nedostajućih vrednosti u GoingTo:
# prazne vrednosti menjamo vrednošću koja se najčešće pojavljuje ("Work").
# Ovo je heuristička metoda koja smanjuje pristrasnost i gubitak informacija.
data$GoingTo[data$GoingTo == ""] <- "Work"
# Pretvaramo GoingTo u faktor (sa eksplicitnim nivoima "Home" i "Work").
# Faktori su kategorijske promenljive koje algoritmi klasifikacije koriste
# da bi prepoznali diskretne klase.
data$GoingTo <- factor(data$GoingTo, levels = c("Home", "Work"))
# Ponovo proveravamo strukturu dataseta da potvrdimo promene.
str(data)
library(fastDummies)
# Dodajemo dummy kolone za 'DayOfWeek' direktno u postojeći data
# data <- dummy_cols(
#   data,
#   select_columns = "DayOfWeek",
#   remove_first_dummy = FALSE,    # TRUE ako želiš da izbaci jednu dummy kolonu (dummy trap)
#   remove_selected_columns = TRUE # TRUE da obriše originalnu 'day' kolonu i zadrži samo dummy-je
# )
dummies <- model.matrix(~ DayOfWeek - 1, data = data)
# spoji dummy-je sa originalnim podacima (ne brišemo DayOfWeek)
data <- cbind(data, dummies)
# ------------------------------------------------------------
# 1. UCITAVANJE I PREGLED PODATAKA
# ------------------------------------------------------------
# Učitavamo CSV fajl sa podacima o vremenima putovanja.
# Parametar stringsAsFactors = F sprečava R da automatski konvertuje string promenljive u faktore.
# To je važno jer želimo sami da kontrolišemo kada i kako se kategorijske promenljive
# pretvaraju u faktore (što je kritično za algoritme klasifikacije).
data <- read.csv("travel-times.csv", stringsAsFactors = F)
# Funkcija str() daje strukturu dataseta:
# prikazuje broj redova i kolona, tip svake kolone (integer, numeric, character, factor),
# kao i prvih nekoliko vrednosti. Ovo je osnovni korak u razumevanju podataka.
str(data)
# Funkcija summary() daje osnovne deskriptivne statistike za svaku kolonu:
# za numeričke kolone to su min, 1. kvartil, medijana, mean, 3. kvartil, max,
# dok za kategorijske prikazuje učestalosti.
# Ove informacije pomažu da se stekne uvid u distribuciju podataka i eventualne anomalije.
summary(data)
# ------------------------------------------------------------
# 2. PROVERA I OBRADA NEDOSTAJUCIH VREDNOSTI
# ------------------------------------------------------------
# Nedostajuće vrednosti mogu biti kodirane na različite načine: kao "", "-", " ", ili formalni NA.
# Ako ih ne obradimo, algoritmi mašinskog učenja će prijaviti grešku jer očekuju kompletne podatke.
# colSums() sabira koliko se puta pojavljuje svaki od ovih obrazaca po kolonama.
colSums(data == "" | data == "-" | data == " " | is.na(data))
# Uklanjamo kolone koje nisu relevantne za modeliranje (Date, StartTime, DayOfWeek).
# Ove promenljive ne nose prediktivnu vrednost, a zadržavanjem bismo mogli da unesemo šum
# ili da komplikujemo model bez realne koristi.
data$Date <- NULL
data$StartTime <- NULL
#data$DayOfWeek <- NULL
# ------------------------------------------------------------
# 3. RAD SA KATEGORIJSKOM PROMENLJIVOM GoingTo
# ------------------------------------------------------------
# Provera tipa podataka u koloni (da bismo znali da li je string ili faktor).
class(data$GoingTo)
# Pregled učestalosti vrednosti u koloni GoingTo.
# Ako ima praznih vrednosti, ovde ih lako primetimo.
table(data$GoingTo)
# Pretvaramo kolonu u character radi fleksibilnije manipulacije.
data$GoingTo <- as.character(data$GoingTo)
# Imputacija nedostajućih vrednosti u GoingTo:
# prazne vrednosti menjamo vrednošću koja se najčešće pojavljuje ("Work").
# Ovo je heuristička metoda koja smanjuje pristrasnost i gubitak informacija.
data$GoingTo[data$GoingTo == ""] <- "Work"
# Pretvaramo GoingTo u faktor (sa eksplicitnim nivoima "Home" i "Work").
# Faktori su kategorijske promenljive koje algoritmi klasifikacije koriste
# da bi prepoznali diskretne klase.
data$GoingTo <- factor(data$GoingTo, levels = c("Home", "Work"))
# Ponovo proveravamo strukturu dataseta da potvrdimo promene.
str(data)
library(fastDummies)
# Dodajemo dummy kolone za 'DayOfWeek' direktno u postojeći data
# data <- dummy_cols(
#   data,
#   select_columns = "DayOfWeek",
#   remove_first_dummy = FALSE,    # TRUE ako želiš da izbaci jednu dummy kolonu (dummy trap)
#   remove_selected_columns = TRUE # TRUE da obriše originalnu 'day' kolonu i zadrži samo dummy-je
# )
dummies <- model.matrix(~ DayOfWeek - 1, data = data)
# spoji dummy-je sa originalnim podacima (ne brišemo DayOfWeek)
data <- cbind(data, dummies)
data$DayOfWeek <- NULL
data <- data[,c(1,11:15,2:10)]
# ------------------------------------------------------------
# 4. RAD SA NUMERIČKOM PROMENLJIVOM FuelEconomy
# ------------------------------------------------------------
# Nedostajuće vrednosti kodiramo kao NA.
data$FuelEconomy[data$FuelEconomy == "" | data$FuelEconomy == " " |
data$FuelEconomy == "-" | is.na(data$FuelEconomy)] <- NA
# Pretvaramo FuelEconomy u numerički tip (da bismo mogli da radimo statističke analize).
data$FuelEconomy <- as.numeric(data$FuelEconomy)
# Testiramo da li FuelEconomy ima normalnu raspodelu (Shapiro-Wilk test).
# Hipoteza H0: podaci su normalno raspoređeni. Ako p < 0.05 → odbacujemo H0.
shapiro.test(na.omit(data$FuelEconomy))
# Pošto podaci nisu normalni, koristimo medijanu kao robusnu meru centralne tendencije.
# Mean je osetljiv na outliere, dok je medijana stabilnija.
medianFuelEconomy <- median(data$FuelEconomy, na.rm = T)
# Sada NA vrednosti zamenjujemo medijanom kolone.
data$FuelEconomy[is.na(data$FuelEconomy)] <- medianFuelEconomy
# ------------------------------------------------------------
# 5. KREIRANJE CILJNE PROMENLJIVE (FEATURE ENGINEERING)
# ------------------------------------------------------------
# Računamo 60-ti percentil zagušenja na 407 autoputu.
percentil60 <- quantile(data$Congestion407, 0.6)
percentil60
# Kreiramo ciljnu promenljivu Take407All:
# logika je da vozači biraju 407 autoput ako je zagušenje manje od 60-tog percentila
# i ako nisu ostavili komentar (npr. nezadovoljstvo).
# Ovo je tipičan primer kreiranja target promenljive na osnovu poslovne logike.
data$Take407All <- ifelse(data$Congestion407 < percentil60 & data$Comments == "",
yes = "Yes", no = "No")
# Pretvaramo target u faktor (binarnu klasnu promenljivu).
data$Take407All <- as.factor(data$Take407All)
# Uklanjamo kolone koje su korišćene za kreiranje targeta
# jer bi njihovo zadržavanje predstavljalo data leakage (curenje podataka).
# Data leakage vodi ka nerealno visokim performansama i lošoj generalizaciji.
data$Congestion407 <- NULL
data$Comments <- NULL
str(data)
# ------------------------------------------------------------
# 6. DETEKCIJA OUTLIERA
# ------------------------------------------------------------
# Koristimo boxplot da vizuelizujemo MaxSpeed i detektujemo outliere.
boxplot(data$MaxSpeed)
# boxplot.stats vraća statističke granice (Q1, Q3, whiskers) i listu outlajera.
boxplot.stats(data$MaxSpeed)
# Broj outlajera u MaxSpeed koloni
length(boxplot.stats(data$MaxSpeed)$out)
# Provera broja outlajera u svim numeričkim kolonama pomoću apply.
apply(data[,2:8], 2, function(x) length(boxplot.stats(x)$out))
# Pretvaranje dummy faktorskih u numericke
data$DayOfWeekMonday    <- as.numeric(as.character(data$DayOfWeekMonday))
data$DayOfWeekTuesday   <- as.numeric(as.character(data$DayOfWeekTuesday))
data$DayOfWeekWednesday <- as.numeric(as.character(data$DayOfWeekWednesday))
data$DayOfWeekThursday  <- as.numeric(as.character(data$DayOfWeekThursday))
data$DayOfWeekFriday    <- as.numeric(as.character(data$DayOfWeekFriday))
str(data)
# ------------------------------------------------------------
# 7. STANDARDIZACIJA PODATAKA
# ------------------------------------------------------------
# Pošto postoji veliki broj outlajera, koristimo robustnu standardizaciju:
# centriranje po medijani i skaliranje po IQR-u.
# Ovo je otpornije od z-score standardizacije (koja koristi mean i standard devijaciju).
data.std <- apply(data[,7:13], 2, function(x) scale(x, median(x), IQR(x)))
# Rezultat apply je matrica → pretvaramo u data.frame radi lakšeg rukovanja.
data.std <- as.data.frame(data.std)
# Dodajemo faktorsku promenljivu GoingTo pretvorenu u numeričku (0/1).
# Ova konverzija omogućava da se kategorijska promenljiva koristi u KNN algoritmu.
data.std$GoingTo <- as.integer(data$GoingTo) - 1
# Dodajemo ciljnu promenljivu u dataset.
data.std$Take407All <- data$Take407All
data.std$DayOfWeekMonday <- data$DayOfWeekMonday
data.std$DayOfWeekTuesday <- data$DayOfWeekTuesday
data.std$DayOfWeekWednesday <- data$DayOfWeekWednesday
data.std$DayOfWeekThursday <- data$DayOfWeekThursday
data.std$DayOfWeekFriday <- data$DayOfWeekFriday
# Raspoređujemo kolone po željenom redosledu radi preglednosti.
data.std <- data.std[,c(8,10:14,1:7,9)]
str(data.std)
summary(data.std)
# ------------------------------------------------------------
# 8. PODELA NA TRAIN I TEST SKUP
# ------------------------------------------------------------
library(caret)
# Setujemo seed da bismo imali reproduktivne rezultate.
set.seed(1010)
# createDataPartition pravi stratifikovanu podelu podataka:
# obezbeđuje da proporcije klasa u trening i test skupu budu slične originalu.
indexes <- createDataPartition(data.std$Take407All, p = 0.8, list = FALSE)
# Trening skup čini 80% podataka, test 20%.
train.data <- data.std[indexes, ]
test.data  <- data.std[-indexes, ]
# Proveravamo proporcije klasa (Yes/No) u celom datasetu, train i test skupu.
prop.table(table(data.std$Take407All))
prop.table(table(train.data$Take407All))
prop.table(table(test.data$Take407All))
# ------------------------------------------------------------
# 9. KNN SA CROSS-VALIDATION I GRID SEARCH
# ------------------------------------------------------------
library(e1071)
# Definišemo strategiju validacije: 10-fold cross-validation.
# Dataset se deli na 10 delova, model se trenira na 9, testira na 1,
# i proces se ponavlja dok svaki deo jednom ne bude test.
numFolds <- trainControl(method = "cv", number = 10)
# Ponovo setujemo seme.
set.seed(1010)
# Definišemo mrežu vrednosti za hiperparametar k.
# Grid search je metoda sistematskog ispitivanja vrednosti hiperparametara.
kGrid  <- expand.grid(.k = seq(from = 3, to = 15, by = 2))
# Treniramo KNN sa različitim vrednostima k i procenjujemo performanse pomoću 10-fold CV.
# Cilj je da pronađemo vrednost k koja daje najbolju prosečnu tačnost.
crossvalidation <- train(
x = train.data[, -14],
y = train.data$Take407All,
method = "knn",
trControl = numFolds,
tuneGrid = kGrid
)
# Prikaz rezultata (accuracy i Kappa po vrednostima k).
crossvalidation
# Grafički prikaz promene tačnosti u zavisnosti od k.
plot(crossvalidation)
# Ekstrakcija najboljeg k (optimalan broj suseda).
bestK <- crossvalidation$bestTune$k
bestK
# ------------------------------------------------------------
# 10. EVALUACIJA MODELA NA TEST SKUPU
# ------------------------------------------------------------
library(class)
# Predikcija pomoću KNN-a na test podacima sa k=13 (odabrano iz CV).
knn.pred <- knn(train = train.data[,-14],
test = test.data[,-14],
cl = train.data$Take407All,
k = 13)
# Ispis predikcija
knn.pred
# Konfuziona matrica poredi stvarne klase (redovi) i predikovane klase (kolone).
# Ona je osnovna alatka za analizu klasifikacionih modela.
cm <- table(test.data$Take407All, knn.pred)
cm
# Funkcija za računanje metrika iz konfuzione matrice.
# Metrike su: Accuracy, Precision, Recall i F1-score.
# One omogućavaju detaljnije razumevanje performansi modela, posebno kod neuravnoteženih klasa.
getEvaluationMetrics <- function(cm){
TP <- cm[2,2]  # True Positives
TN <- cm[1,1]  # True Negatives
FP <- cm[1,2]  # False Positives
FN <- cm[2,1]  # False Negatives
# Accuracy = udeo ispravno klasifikovanih instanci
accuracy  <- (TP+TN)/(TP+TN+FP+FN)
# Precision = udeo ispravnih pozitivnih predikcija u svim predikcijama pozitivne klase
precision <- TP/(TP+FP)
# Recall (senzitivnost) = udeo prepoznatih pozitivnih primera u svim stvarnim pozitivnim primerima
recall <- TP/(TP+FN)
# F1-score = harmonijska sredina Precision i Recall,
# koristi se kada je važno postići balans između njih.
f1 <- (2*precision*recall)/(precision+recall)
c(
accuracy = accuracy,
precision = precision,
recall = recall,
f1 = f1
)
}
# Računamo evaluacione metrike na osnovu test skupa.
getEvaluationMetrics(cm)
# ------------------------------------------------------------
# 1. UCITAVANJE I PREGLED PODATAKA
# ------------------------------------------------------------
# Učitavamo CSV fajl sa podacima o vremenima putovanja.
# Parametar stringsAsFactors = F sprečava R da automatski konvertuje string promenljive u faktore.
# To je važno jer želimo sami da kontrolišemo kada i kako se kategorijske promenljive
# pretvaraju u faktore (što je kritično za algoritme klasifikacije).
data <- read.csv("travel-times.csv", stringsAsFactors = F)
# Funkcija str() daje strukturu dataseta:
# prikazuje broj redova i kolona, tip svake kolone (integer, numeric, character, factor),
# kao i prvih nekoliko vrednosti. Ovo je osnovni korak u razumevanju podataka.
str(data)
# Funkcija summary() daje osnovne deskriptivne statistike za svaku kolonu:
# za numeričke kolone to su min, 1. kvartil, medijana, mean, 3. kvartil, max,
# dok za kategorijske prikazuje učestalosti.
# Ove informacije pomažu da se stekne uvid u distribuciju podataka i eventualne anomalije.
summary(data)
# ------------------------------------------------------------
# 2. PROVERA I OBRADA NEDOSTAJUCIH VREDNOSTI
# ------------------------------------------------------------
# Nedostajuće vrednosti mogu biti kodirane na različite načine: kao "", "-", " ", ili formalni NA.
# Ako ih ne obradimo, algoritmi mašinskog učenja će prijaviti grešku jer očekuju kompletne podatke.
# colSums() sabira koliko se puta pojavljuje svaki od ovih obrazaca po kolonama.
colSums(data == "" | data == "-" | data == " " | is.na(data))
# Uklanjamo kolone koje nisu relevantne za modeliranje (Date, StartTime, DayOfWeek).
# Ove promenljive ne nose prediktivnu vrednost, a zadržavanjem bismo mogli da unesemo šum
# ili da komplikujemo model bez realne koristi.
data$Date <- NULL
data$StartTime <- NULL
#data$DayOfWeek <- NULL
# ------------------------------------------------------------
# 3. RAD SA KATEGORIJSKOM PROMENLJIVOM GoingTo
# ------------------------------------------------------------
# Provera tipa podataka u koloni (da bismo znali da li je string ili faktor).
class(data$GoingTo)
# Pregled učestalosti vrednosti u koloni GoingTo.
# Ako ima praznih vrednosti, ovde ih lako primetimo.
table(data$GoingTo)
# Pretvaramo kolonu u character radi fleksibilnije manipulacije.
data$GoingTo <- as.character(data$GoingTo)
# Imputacija nedostajućih vrednosti u GoingTo:
# prazne vrednosti menjamo vrednošću koja se najčešće pojavljuje ("Work").
# Ovo je heuristička metoda koja smanjuje pristrasnost i gubitak informacija.
data$GoingTo[data$GoingTo == ""] <- "Work"
# Pretvaramo GoingTo u faktor (sa eksplicitnim nivoima "Home" i "Work").
# Faktori su kategorijske promenljive koje algoritmi klasifikacije koriste
# da bi prepoznali diskretne klase.
data$GoingTo <- factor(data$GoingTo, levels = c("Home", "Work"))
# Ponovo proveravamo strukturu dataseta da potvrdimo promene.
str(data)
#library(fastDummies)
# Dodajemo dummy kolone za 'DayOfWeek' direktno u postojeći data
# data <- dummy_cols(
#   data,
#   select_columns = "DayOfWeek",
#   remove_first_dummy = FALSE,    # TRUE ako želiš da izbaci jednu dummy kolonu (dummy trap)
#   remove_selected_columns = TRUE # TRUE da obriše originalnu 'day' kolonu i zadrži samo dummy-je
# )
#pravimo dummy promenjive
dummies <- model.matrix(~ DayOfWeek - 1, data = data)
# spoji dummy-je sa originalnim podacima
data <- cbind(data, dummies)
# uklanjamo DayOfWeek
data$DayOfWeek <- NULL
# sredivanje kolona
data <- data[,c(1,11:15,2:10)]
# ------------------------------------------------------------
# 4. RAD SA NUMERIČKOM PROMENLJIVOM FuelEconomy
# ------------------------------------------------------------
# Nedostajuće vrednosti kodiramo kao NA.
data$FuelEconomy[data$FuelEconomy == "" | data$FuelEconomy == " " |
data$FuelEconomy == "-" | is.na(data$FuelEconomy)] <- NA
# Pretvaramo FuelEconomy u numerički tip (da bismo mogli da radimo statističke analize).
data$FuelEconomy <- as.numeric(data$FuelEconomy)
# Testiramo da li FuelEconomy ima normalnu raspodelu (Shapiro-Wilk test).
# Hipoteza H0: podaci su normalno raspoređeni. Ako p < 0.05 → odbacujemo H0.
shapiro.test(na.omit(data$FuelEconomy))
# Pošto podaci nisu normalni, koristimo medijanu kao robusnu meru centralne tendencije.
# Mean je osetljiv na outliere, dok je medijana stabilnija.
medianFuelEconomy <- median(data$FuelEconomy, na.rm = T)
# Sada NA vrednosti zamenjujemo medijanom kolone.
data$FuelEconomy[is.na(data$FuelEconomy)] <- medianFuelEconomy
# ------------------------------------------------------------
# 5. KREIRANJE CILJNE PROMENLJIVE (FEATURE ENGINEERING)
# ------------------------------------------------------------
# Računamo 60-ti percentil zagušenja na 407 autoputu.
percentil60 <- quantile(data$Congestion407, 0.6)
percentil60
# Kreiramo ciljnu promenljivu Take407All:
# logika je da vozači biraju 407 autoput ako je zagušenje manje od 60-tog percentila
# i ako nisu ostavili komentar (npr. nezadovoljstvo).
# Ovo je tipičan primer kreiranja target promenljive na osnovu poslovne logike.
data$Take407All <- ifelse(data$Congestion407 < percentil60 & data$Comments == "",
yes = "Yes", no = "No")
# Pretvaramo target u faktor (binarnu klasnu promenljivu).
data$Take407All <- as.factor(data$Take407All)
# Uklanjamo kolone koje su korišćene za kreiranje targeta
# jer bi njihovo zadržavanje predstavljalo data leakage (curenje podataka).
# Data leakage vodi ka nerealno visokim performansama i lošoj generalizaciji.
data$Congestion407 <- NULL
data$Comments <- NULL
str(data)
# ------------------------------------------------------------
# 6. DETEKCIJA OUTLIERA
# ------------------------------------------------------------
# Koristimo boxplot da vizuelizujemo MaxSpeed i detektujemo outliere.
boxplot(data$MaxSpeed)
# boxplot.stats vraća statističke granice (Q1, Q3, whiskers) i listu outlajera.
boxplot.stats(data$MaxSpeed)
# Broj outlajera u MaxSpeed koloni
length(boxplot.stats(data$MaxSpeed)$out)
# Provera broja outlajera u svim numeričkim kolonama pomoću apply.
apply(data[,2:8], 2, function(x) length(boxplot.stats(x)$out))
# Pretvaranje dummy faktorskih u numericke
data$DayOfWeekMonday    <- as.numeric(as.character(data$DayOfWeekMonday))
data$DayOfWeekTuesday   <- as.numeric(as.character(data$DayOfWeekTuesday))
data$DayOfWeekWednesday <- as.numeric(as.character(data$DayOfWeekWednesday))
data$DayOfWeekThursday  <- as.numeric(as.character(data$DayOfWeekThursday))
data$DayOfWeekFriday    <- as.numeric(as.character(data$DayOfWeekFriday))
str(data)
# ------------------------------------------------------------
# 7. STANDARDIZACIJA PODATAKA
# ------------------------------------------------------------
# Pošto postoji veliki broj outlajera, koristimo robustnu standardizaciju:
# centriranje po medijani i skaliranje po IQR-u.
# Ovo je otpornije od z-score standardizacije (koja koristi mean i standard devijaciju).
data.std <- apply(data[,7:13], 2, function(x) scale(x, median(x), IQR(x)))
# Rezultat apply je matrica → pretvaramo u data.frame radi lakšeg rukovanja.
data.std <- as.data.frame(data.std)
# Dodajemo faktorsku promenljivu GoingTo pretvorenu u numeričku (0/1).
# Ova konverzija omogućava da se kategorijska promenljiva koristi u KNN algoritmu.
data.std$GoingTo <- as.integer(data$GoingTo) - 1
# Dodajemo ciljnu promenljivu u dataset.
data.std$Take407All <- data$Take407All
data.std$DayOfWeekMonday <- data$DayOfWeekMonday
data.std$DayOfWeekTuesday <- data$DayOfWeekTuesday
data.std$DayOfWeekWednesday <- data$DayOfWeekWednesday
data.std$DayOfWeekThursday <- data$DayOfWeekThursday
data.std$DayOfWeekFriday <- data$DayOfWeekFriday
# Raspoređujemo kolone po željenom redosledu radi preglednosti.
data.std <- data.std[,c(8,10:14,1:7,9)]
str(data.std)
summary(data.std)
# ------------------------------------------------------------
# 8. PODELA NA TRAIN I TEST SKUP
# ------------------------------------------------------------
library(caret)
# Setujemo seed da bismo imali reproduktivne rezultate.
set.seed(1010)
# createDataPartition pravi stratifikovanu podelu podataka:
# obezbeđuje da proporcije klasa u trening i test skupu budu slične originalu.
indexes <- createDataPartition(data.std$Take407All, p = 0.8, list = FALSE)
# Trening skup čini 80% podataka, test 20%.
train.data <- data.std[indexes, ]
test.data  <- data.std[-indexes, ]
# Proveravamo proporcije klasa (Yes/No) u celom datasetu, train i test skupu.
prop.table(table(data.std$Take407All))
prop.table(table(train.data$Take407All))
prop.table(table(test.data$Take407All))
# ------------------------------------------------------------
# 9. KNN SA CROSS-VALIDATION I GRID SEARCH
# ------------------------------------------------------------
library(e1071)
# Definišemo strategiju validacije: 10-fold cross-validation.
# Dataset se deli na 10 delova, model se trenira na 9, testira na 1,
# i proces se ponavlja dok svaki deo jednom ne bude test.
numFolds <- trainControl(method = "cv", number = 10)
# Ponovo setujemo seme.
set.seed(1010)
# Definišemo mrežu vrednosti za hiperparametar k.
# Grid search je metoda sistematskog ispitivanja vrednosti hiperparametara.
kGrid  <- expand.grid(.k = seq(from = 3, to = 15, by = 2))
# Treniramo KNN sa različitim vrednostima k i procenjujemo performanse pomoću 10-fold CV.
# Cilj je da pronađemo vrednost k koja daje najbolju prosečnu tačnost.
crossvalidation <- train(
x = train.data[, -14],
y = train.data$Take407All,
method = "knn",
trControl = numFolds,
tuneGrid = kGrid
)
# Prikaz rezultata (accuracy i Kappa po vrednostima k).
crossvalidation
# Grafički prikaz promene tačnosti u zavisnosti od k.
plot(crossvalidation)
# Ekstrakcija najboljeg k (optimalan broj suseda).
bestK <- crossvalidation$bestTune$k
bestK
# ------------------------------------------------------------
# 10. EVALUACIJA MODELA NA TEST SKUPU
# ------------------------------------------------------------
library(class)
# Predikcija pomoću KNN-a na test podacima sa k=13 (odabrano iz CV).
knn.pred <- knn(train = train.data[,-14],
test = test.data[,-14],
cl = train.data$Take407All,
k = 13)
# Ispis predikcija
knn.pred
# Konfuziona matrica poredi stvarne klase (redovi) i predikovane klase (kolone).
# Ona je osnovna alatka za analizu klasifikacionih modela.
cm <- table(test.data$Take407All, knn.pred)
cm
# Funkcija za računanje metrika iz konfuzione matrice.
# Metrike su: Accuracy, Precision, Recall i F1-score.
# One omogućavaju detaljnije razumevanje performansi modela, posebno kod neuravnoteženih klasa.
getEvaluationMetrics <- function(cm){
TP <- cm[2,2]  # True Positives
TN <- cm[1,1]  # True Negatives
FP <- cm[1,2]  # False Positives
FN <- cm[2,1]  # False Negatives
# Accuracy = udeo ispravno klasifikovanih instanci
accuracy  <- (TP+TN)/(TP+TN+FP+FN)
# Precision = udeo ispravnih pozitivnih predikcija u svim predikcijama pozitivne klase
precision <- TP/(TP+FP)
# Recall (senzitivnost) = udeo prepoznatih pozitivnih primera u svim stvarnim pozitivnim primerima
recall <- TP/(TP+FN)
# F1-score = harmonijska sredina Precision i Recall,
# koristi se kada je važno postići balans između njih.
f1 <- (2*precision*recall)/(precision+recall)
c(
accuracy = accuracy,
precision = precision,
recall = recall,
f1 = f1
)
}
# Računamo evaluacione metrike na osnovu test skupa.
getEvaluationMetrics(cm)
